{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ecbc533",
   "metadata": {},
   "source": [
    "## 1. ChatPromt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efb25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import PromptTemplate,load_prompt\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatOpenAI()\n",
    "\n",
    "st.header('Reasearch Tool')\n",
    "\n",
    "paper_input = st.selectbox( \"Select Research Paper Name\", [\"Attention Is All You Need\", \"BERT: Pre-training of Deep Bidirectional Transformers\", \"GPT-3: Language Models are Few-Shot Learners\", \"Diffusion Models Beat GANs on Image Synthesis\"] )\n",
    "\n",
    "style_input = st.selectbox( \"Select Explanation Style\", [\"Beginner-Friendly\", \"Technical\", \"Code-Oriented\", \"Mathematical\"] ) \n",
    "\n",
    "length_input = st.selectbox( \"Select Explanation Length\", [\"Short (1-2 paragraphs)\", \"Medium (3-5 paragraphs)\", \"Long (detailed explanation)\"] )\n",
    "\n",
    "template = load_prompt('template.json')\n",
    "\n",
    "template2 = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    resaerch paper :{Paper}\n",
    "    lengeth: {Length}\n",
    "    style: {style}\n",
    "    \"\"\"\n",
    "    input_variables=['Paper','Length','style']\n",
    "    validate_template=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "if st.button('Summarize'):\n",
    "    chain = template | model\n",
    "    result = chain.invoke({\n",
    "        'paper_input':paper_input,\n",
    "        'style_input':style_input,\n",
    "        'length_input':length_input\n",
    "    })\n",
    "    st.write(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22844744",
   "metadata": {},
   "source": [
    "#### Promt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# detailed way\n",
    "template2 = PromptTemplate(\n",
    "    template='Greet this person in 5 languages. The name of the person is {name}',\n",
    "    input_variables=['name']\n",
    ")\n",
    "\n",
    "# fill the values of the placeholders\n",
    "prompt = template2.invoke({'name':'nitish'})\n",
    "\n",
    "result = model.invoke(prompt)\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b98dd7",
   "metadata": {},
   "source": [
    "#### Prompt Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Please summarize the research paper titled \"{paper_input}\" with the following specifications:\n",
    "Explanation Style: {style_input}  \n",
    "Explanation Length: {length_input}  \n",
    "1. Mathematical Details:  \n",
    "   - Include relevant mathematical equations if present in the paper.  \n",
    "   - Explain the mathematical concepts using simple, intuitive code snippets where applicable.  \n",
    "2. Analogies:  \n",
    "   - Use relatable analogies to simplify complex ideas.  \n",
    "If certain information is not available in the paper, respond with: \"Insufficient information available\" instead of guessing.  \n",
    "Ensure the summary is clear, accurate, and aligned with the provided style and length.\n",
    "\"\"\",\n",
    "input_variables=['paper_input', 'style_input','length_input'],\n",
    "validate_template=True\n",
    ")\n",
    "\n",
    "template.save('template.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537dfee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template.json\n",
    "\n",
    "{\n",
    "    \"name\": null,\n",
    "    \"input_variables\": [\n",
    "        \"length_input\",\n",
    "        \"paper_input\",\n",
    "        \"style_input\"\n",
    "    ],\n",
    "    \"optional_variables\": [],\n",
    "    \"output_parser\": null,\n",
    "    \"partial_variables\": {},\n",
    "    \"metadata\": null,\n",
    "    \"tags\": null,\n",
    "    \"template\": \"\\nPlease summarize the research paper titled \\\"{paper_input}\\\" with the following specifications:\\nExplanation Style: {style_input}  \\nExplanation Length: {length_input}  \\n1. Mathematical Details:  \\n   - Include relevant mathematical equations if present in the paper.  \\n   - Explain the mathematical concepts using simple, intuitive code snippets where applicable.  \\n2. Analogies:  \\n   - Use relatable analogies to simplify complex ideas.  \\nIf certain information is not available in the paper, respond with: \\\"Insufficient information available\\\" instead of guessing.  \\nEnsure the summary is clear, accurate, and aligned with the provided style and length.\\n\",\n",
    "    \"template_format\": \"f-string\",\n",
    "    \"validate_template\": true,\n",
    "    \"_type\": \"prompt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c54b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Json Template\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import PromptTemplate,load_prompt\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatOpenAI()\n",
    "\n",
    "st.header('Reasearch Tool')\n",
    "\n",
    "paper_input = st.selectbox( \"Select Research Paper Name\", [\"Attention Is All You Need\", \"BERT: Pre-training of Deep Bidirectional Transformers\", \"GPT-3: Language Models are Few-Shot Learners\", \"Diffusion Models Beat GANs on Image Synthesis\"] )\n",
    "\n",
    "style_input = st.selectbox( \"Select Explanation Style\", [\"Beginner-Friendly\", \"Technical\", \"Code-Oriented\", \"Mathematical\"] ) \n",
    "\n",
    "length_input = st.selectbox( \"Select Explanation Length\", [\"Short (1-2 paragraphs)\", \"Medium (3-5 paragraphs)\", \"Long (detailed explanation)\"] )\n",
    "\n",
    "template = load_prompt('template.json')\n",
    "\n",
    "\n",
    "\n",
    "if st.button('Summarize'):\n",
    "    chain = template | model\n",
    "    result = chain.invoke({\n",
    "        'paper_input':paper_input,\n",
    "        'style_input':style_input,\n",
    "        'length_input':length_input\n",
    "    })\n",
    "    st.write(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112d6e48",
   "metadata": {},
   "source": [
    "#### Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da449be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content='You are a helpful assistant'),\n",
    "    HumanMessage(content='Tell me about LangChain')\n",
    "]\n",
    "\n",
    "result = model.invoke(messages)\n",
    "\n",
    "messages.append(AIMessage(content=result.content))\n",
    "\n",
    "print(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92825cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate([\n",
    "    ('system', 'You are a helpful {domain} expert'),\n",
    "    ('human', 'Explain in simple terms, what is {topic}')\n",
    "])\n",
    "\n",
    "prompt = chat_template.invoke({'domain':'cricket','topic':'Dusra'})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de0ffa",
   "metadata": {},
   "source": [
    "#### Message PlaceHolder ( Chat history )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5001e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### chat_History.txt\n",
    "\n",
    "HumanMessage(content=\"I want to request a refund for my order #12345.\")\n",
    "AIMessage(content=\"Your refund request for order #12345 has been initiated. It will be processed in 3-5 business days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e541ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# chat template\n",
    "chat_template = ChatPromptTemplate([\n",
    "    ('system','You are a helpful customer support agent'),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    ('human','{query}')\n",
    "])\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "# load chat history\n",
    "with open('chat_history.txt') as f:\n",
    "    chat_history.extend(f.readlines())\n",
    "\n",
    "print(chat_history)\n",
    "\n",
    "# create prompt\n",
    "prompt = chat_template.invoke({'chat_history':chat_history, 'query':'Where is my refund'})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2080bdbd",
   "metadata": {},
   "source": [
    "#### AI ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chat_history = [\n",
    "    SystemMessage(content='You are a helpful AI assistant')\n",
    "]\n",
    "\n",
    "while True:\n",
    "    user_input = input('You: ')\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    if user_input == 'exit':\n",
    "        break\n",
    "    result = model.invoke(chat_history)\n",
    "    chat_history.append(AIMessage(content=result.content))\n",
    "    print(\"AI: \",result.content)\n",
    "\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643c4402",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d010395",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cb841a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0fc0361",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7b144f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f37db4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
